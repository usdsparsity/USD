Cette différence de comportement entre ResNet50 et ViT-B lors du fine-tuning sur CIFAR-100 est fascinante et s'explique par plusieurs facteurs fondamentaux liés à l'architecture de ces réseaux.

## Différences architecturales fondamentales

ResNet50 a une architecture CNN (réseau de neurones convolutionnels) qui possède des propriétés intrinsèques favorables au transfert d'apprentissage, notamment :

- **Biais d'induction spatial fort** : Les couches de convolution intègrent naturellement des hypothèses sur les relations spatiales locales dans les images
- **Invariance à la translation** : Grâce au pooling et aux convolutions, une capacité native à reconnaître des motifs indépendamment de leur position exacte

En revanche, le ViT (Vision Transformer) :

- **Ne possède pas ces biais d'induction spatiale** : Il doit apprendre les relations spatiales à partir des données
- **Traite l'image comme une séquence de patches** : La compréhension spatiale se construit principalement via l'attention

## Adaptation aux caractéristiques de CIFAR-100

CIFAR-100 contient des images de petite taille (32×32 pixels) alors qu'ImageNet contient des images beaucoup plus grandes (224×224 pixels). Cela crée des défis spécifiques :

1. **Pour ResNet50** : L'architecture CNN s'adapte bien aux échelles variées grâce à sa hiérarchie de caractéristiques allant du local au global
   
2. **Pour ViT** : 
   - La division en patches fixes (typiquement 16×16) est problématique sur des images 32×32
   - Le nombre total de patches est fortement réduit (4 patches seulement pour une image 32×32)
   - L'attention apprend des relations globales qui peuvent être trop générales pour CIFAR

## Besoins en données pour l'apprentissage

Les Transformers sont connus pour leur faim de données :

- **ResNet50** : Grâce à ses biais d'induction spatiale, il peut généraliser efficacement avec moins d'exemples
- **ViT** : Sans ces biais intégrés, il nécessite beaucoup plus de données pour atteindre des performances similaires

## Stratégies pour améliorer le fine-tuning du ViT sur CIFAR-100

Pour accélérer l'adaptation du ViT à CIFAR-100 :

1. **Adapter la taille des patches** : Utiliser des patches plus petits (8×8 ou 4×4)
2. **Augmenter les données** plus aggressivement
3. **Utiliser un learning rate plus faible** pour le ViT
4. **Considérer un ViT hybride** avec quelques couches convolutives au début

Cette différence de comportement illustre un principe fondamental en apprentissage profond : les biais d'induction architecturaux jouent un rôle crucial dans le transfert d'apprentissage, et les architectures CNN comme ResNet possèdent des avantages inhérents pour le traitement d'images à différentes échelles.